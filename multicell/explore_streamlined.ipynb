{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# path hack for relative import in jupyter notebook\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# LIBRARY GLOBAL MODS\n",
    "CELLTYPES = os.path.dirname(os.path.abspath(''))\n",
    "sys.path.append(CELLTYPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import umap\n",
    "import time\n",
    "\n",
    "sns.set(style='white', context='notebook', rc={'figure.figsize':(14,10)})\n",
    "\n",
    "from utils.file_io import RUNS_FOLDER\n",
    "\n",
    "NOTEBOOK_OUTDIR = RUNS_FOLDER + os.sep + 'explore' + os.sep + 'nb_streamlined'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multicell.unsupervised_helper import \\\n",
    "    plotly_express_embedding, generate_control_data, plot_given_multicell, make_dimreduce_object\n",
    "\n",
    "from singlecell.singlecell_linalg import sorted_eig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings: dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these set the defaults for modifications introduced in main\n",
    "REDUCER_SEED = 0\n",
    "REDUCER_COMPONENTS = 2\n",
    "VALID_REDUCERS = ['umap', 'tsne', 'pca']\n",
    "REDUCERS_TO_USE = ['umap']\n",
    "assert REDUCERS_TO_USE == ['umap']  # for now, extend later\n",
    "\n",
    "# see defaults: https://umap-learn.readthedocs.io/en/latest/api.html\n",
    "\"\"\"AP_KWARGS = {\n",
    "    'random_state': REDUCER_SEED,\n",
    "    'n_components': REDUCER_COMPONENTS,\n",
    "    'metric': 'euclidean',\n",
    "    'init': 'spectral',\n",
    "    'unique': False,\n",
    "    'n_neighbors': 15,\n",
    "    'min_dist': 0.1,\n",
    "    'spread': 1.0,\n",
    "}\"\"\"\n",
    "UMAP_KWARGS = {\n",
    "    'random_state': REDUCER_SEED,\n",
    "    'n_components': REDUCER_COMPONENTS,\n",
    "    'metric': 'euclidean',\n",
    "    'init': 'spectral',\n",
    "    'unique': False,\n",
    "    'n_neighbors': 60,\n",
    "    'min_dist': 0.1,\n",
    "    'spread': 1.0,\n",
    "}\n",
    "TSNE_KWARGS = {\n",
    "    'random_state': REDUCER_SEED,\n",
    "    'n_components': REDUCER_COMPONENTS,\n",
    "    'metric': 'euclidean',\n",
    "    'init': 'random',\n",
    "    'perplexity': 30.0,\n",
    "}\n",
    "PCA_KWARGS = {\n",
    "    'n_components': REDUCER_COMPONENTS,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meanfield version of `make_dimreduce_object`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from singlecell.singlecell_functions import label_to_state, state_to_label\n",
    "\n",
    "def LOCAL_make_dimreduce_object_meanfield(\n",
    "    data_subdict, flag_control=False, nsubsample=None,\n",
    "    use_01=True, jitter_scale=0.0, reducers=REDUCERS_TO_USE,\n",
    "    umap_kwargs=UMAP_KWARGS, pca_kwargs=PCA_KWARGS, tsne_kwargs=TSNE_KWARGS, \n",
    "    step=None, remove_symmetry_ordering=True):\n",
    "    \"\"\"\n",
    "    :param data_subdict:\n",
    "    :param flag_control:\n",
    "    :param nsubsample:\n",
    "    :param use_01:\n",
    "    :param jitter_scale:\n",
    "    :param umap_kwargs:\n",
    "    :param pca_kwargs:\n",
    "    :param tsne_kwargs:\n",
    "    :param step:  step of the simulation e.g. 'X_aggregate_7.npz'\n",
    "        if None, then use 'X_aggregate.npz' (corresponds to last step)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if flag_control:\n",
    "        data_subdict['algos'] = {}\n",
    "        #X = data_subdict['data']\n",
    "        if nsubsample is not None:\n",
    "            data_subdict['data'] = data_subdict['data'][0:nsubsample, :]\n",
    "    else:\n",
    "        manyruns_path = data_subdict['path']\n",
    "\n",
    "        #smod = ''\n",
    "        smod = '_last'  # '' is old style, '_last' is new style\n",
    "        if step is not None:\n",
    "            smod = '_%d' % step\n",
    "\n",
    "        agg_dir = manyruns_path + os.sep + 'aggregate'\n",
    "        fpath_state = agg_dir + os.sep + 'X_aggregate%s.npz' % smod\n",
    "        fpath_energy = agg_dir + os.sep + 'X_energy%s.npz' % smod\n",
    "        fpath_pickle = manyruns_path + os.sep + 'multicell_template.pkl'\n",
    "        X = np.load(fpath_state)['arr_0'].T  # umap wants transpose\n",
    "        X_energies = np.load(fpath_energy)['arr_0'].T  # umap wants transpose (?)\n",
    "        \n",
    "        with open(fpath_pickle, 'rb') as pickle_file:\n",
    "            multicell_template = pickle.load(pickle_file)  # unpickling multicell object\n",
    "            num_cells = multicell_template.num_cells\n",
    "            num_genes = multicell_template.num_genes\n",
    "            \n",
    "        if remove_symmetry_ordering:\n",
    "            assert nsubsample is None\n",
    "            \n",
    "            def transform_X_meanfield(X_orig):\n",
    "                # Note: this should only be used when  'meanfield' interactions are used -- we discard specific orderings\n",
    "                # 1) produce 'ordered' version of each lattice state\n",
    "                # 2) keep only unique copies of the ordering\n",
    "                num_runs, total_spins = X_orig.shape\n",
    "                assert total_spins == num_cells * num_genes\n",
    "                \n",
    "                X_cells_as_cols = np.copy(X_orig)\n",
    "                X_cells_as_cols = np.reshape(X_cells_as_cols, (-1, num_genes, num_cells), order='F')\n",
    "                X_as_labels = np.zeros((num_runs, num_cells), dtype=int)\n",
    "                X_meanfield = np.zeros((num_runs, total_spins), dtype=int)\n",
    "                \n",
    "                # A) create X_as_labels (cells as integers 0 to 2^N)\n",
    "                for k in range(num_runs):\n",
    "                    for c in range(num_cells):\n",
    "                        cellstate = X_cells_as_cols[k, :, c]\n",
    "                        X_as_labels[k, c] = state_to_label(cellstate)\n",
    "                    \n",
    "                    # Perform sorting (this requires meanfield case)\n",
    "                    X_as_labels[k, :] = np.sort(X_as_labels[k, :])\n",
    "                    \n",
    "                    # Tranform original datase\n",
    "                    for c in range(num_cells):\n",
    "                        X_cells_as_cols[k, :, c] = label_to_state(X_as_labels[k, c], num_genes)\n",
    "\n",
    "                    # Reshape to single axis: num_genes * num_cells\n",
    "                    X_meanfield[k, :] = X_cells_as_cols[k, :, :].reshape(total_spins)\n",
    "                            \n",
    "                # C) identify duplicate runs\n",
    "                # TODO later -- for now we will keep the runs as duplicates, umap will handle it naturally\n",
    "                return X_meanfield\n",
    "            \n",
    "            #indices_to_keep = select_indices_to_keep()\n",
    "            #X = X[indices_to_keep, :] \n",
    "            #X_energies = X[indices_to_keep, :] \n",
    "            X_new = transform_X_meanfield(X)\n",
    "            X = X_new\n",
    "\n",
    "        if nsubsample is not None:\n",
    "            X = X[0:nsubsample, :]\n",
    "            X_energies = X_energies[0:nsubsample, :]\n",
    "\n",
    "        # store data and metadata in datasets object\n",
    "        num_runs, total_spins = X.shape\n",
    "        data_subdict['data'] = X\n",
    "        data_subdict['index'] = list(range(num_runs))\n",
    "        data_subdict['energies'] = X_energies\n",
    "        data_subdict['num_runs'] = num_runs\n",
    "        data_subdict['total_spins'] = total_spins\n",
    "        data_subdict['multicell_template'] = multicell_template  # not needed? stored already\n",
    "        data_subdict['algos'] = {}\n",
    "\n",
    "    # binarization step needed for umap's binary metrics\n",
    "    #  - convert +1, -1 to +1, 0\n",
    "    if use_01:\n",
    "        data_subdict['data'] = (1 + data_subdict['data']) / 2.0\n",
    "        data_subdict['data'] = data_subdict['data'].astype(int)\n",
    "        #X = (1 + X) / 2.0\n",
    "        #X = X.astype(int)\n",
    "\n",
    "    if jitter_scale > 0:\n",
    "        # add gaussian noise to data with std=jitter_scale\n",
    "        jitter = np.random.normal(0.0, jitter_scale, size=data_subdict['data'].shape)\n",
    "        data_subdict['data'] = data_subdict['data'] + jitter\n",
    "\n",
    "    # perform dimension reduction\n",
    "    for algo in reducers:\n",
    "        assert algo in VALID_REDUCERS\n",
    "        data_subdict['algos'][algo] = {}\n",
    "\n",
    "        t1 = time.time()\n",
    "        if algo == 'umap':\n",
    "            data_subdict['algos'][algo]['reducer'] = umap.UMAP(**umap_kwargs)\n",
    "            data_subdict['algos'][algo]['reducer'].fit(data_subdict['data'])\n",
    "            embedding = data_subdict['algos'][algo]['reducer'].transform(\n",
    "                data_subdict['data']\n",
    "            )\n",
    "            data_subdict['algos'][algo]['embedding'] = embedding\n",
    "        elif algo == 'pca':\n",
    "            data_subdict['algos'][algo]['reducer'] = PCA(**pca_kwargs)\n",
    "            embedding = data_subdict['algos'][algo]['reducer'].fit_transform(\n",
    "                data_subdict['data']\n",
    "            )\n",
    "            data_subdict['algos'][algo]['embedding'] = embedding\n",
    "        else:\n",
    "            assert algo == 'tsne'\n",
    "            data_subdict['algos'][algo]['reducer'] = TSNE(**tsne_kwargs)\n",
    "            embedding = data_subdict['algos'][algo]['reducer'].fit_transform(\n",
    "                data_subdict['data']\n",
    "            )\n",
    "            data_subdict['algos'][algo]['embedding'] = embedding\n",
    "        print('Time to fit (%s): %.2f sec' % (algo, (time.time() - t1)))\n",
    "\n",
    "    return data_subdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0) Dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) load dataset\n",
    "gamma = 1.0\n",
    "\n",
    "manyruns_dirname = 'Wrandom0_gamma%.2f_10k_periodic_R1_p3_M100_machineEps' % gamma\n",
    "#manyruns_dirname = 'Wmaze15_R5_gamma%.2f_10k_p3_M100' % gamma\n",
    "#manyruns_dirname = 'Wrandom0_gamma%.2f_10k_fixedorder_p3_M4' % gamma\n",
    "#manyruns_dirname = 'Wrandom0_gamma%.2f_10k_periodic_fixedorderV3_p3_M100' % gamma\n",
    "#manyruns_dirname = 'Wrandom0_gamma%.2f_10k_periodic_fixedorderV3_p3_M100' % gamma\n",
    "#manyruns_dirname = 'Wvary_s0randomInit_gamma%.2f_10k_periodic_fixedorderV3_p3_M100' % gamma\n",
    "manyruns_path = RUNS_FOLDER + os.sep + 'multicell_manyruns' + os.sep + manyruns_dirname\n",
    "    \n",
    "# Step 0) load data\n",
    "data_subdict = {'label': manyruns_dirname,\n",
    "                'path': manyruns_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) DImension reduction (store in data_subdict object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_01 = False\n",
    "nsubsample = None\n",
    "meanfield_variant = True\n",
    "\n",
    "if meanfield_variant:\n",
    "    dimereduce_fn = LOCAL_make_dimreduce_object_meanfield\n",
    "else:\n",
    "    dimereduce_fn = make_dimreduce_object\n",
    "    \n",
    "    \n",
    "# 1) fill out data_subdict (dim reduce)\n",
    "data_subdict = dimereduce_fn(\n",
    "    data_subdict, \n",
    "    nsubsample=nsubsample, \n",
    "    flag_control=False,\n",
    "    use_01=use_01, \n",
    "    jitter_scale=0.0,\n",
    "    reducers=REDUCERS_TO_USE,\n",
    "    umap_kwargs=UMAP_KWARGS, tsne_kwargs=TSNE_KWARGS, pca_kwargs=PCA_KWARGS,\n",
    "    step=None)\n",
    "#save_dimreduce_object(datasets[idx], fpath)  # save to file (joblib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_subdict.keys())\n",
    "print(data_subdict['algos']['umap'].keys())\n",
    "print(data_subdict['algos']['umap']['embedding'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Visualize umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) visualize data_subdict\n",
    "plotly_express_embedding(data_subdict, \n",
    "                         color_by_index=False, \n",
    "                         as_landscape=False, \n",
    "                         fmod='jupyter', \n",
    "                         show=False, \n",
    "                         dirpath=NOTEBOOK_OUTDIR, \n",
    "                         surf=False, \n",
    "                         step=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering and plotting of sample points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\"\"\"\n",
    "NOTES:\n",
    "- kmeans.labels_ will return [cluster_7, cluster_5, ..., cluster_0] -- cluster id for each data point\n",
    "- also have: kmeans.predict([[0, 0], [12, 3]])\n",
    "- also have: kmeans.cluster_centers_\n",
    "\"\"\"\n",
    "\n",
    "#kmeans_highdim = KMeans(n_clusters=8, random_state=0).fit(X)\n",
    "N_CLUSTERS = 30\n",
    "CLUSTER_COLOURS = {i: 'blue' for i in range(N_CLUSTERS)}  # TODO implement, currently unused\n",
    "assert N_CLUSTERS <= len(CLUSTER_COLOURS.keys())\n",
    "\n",
    "kmeans_lowdim = KMeans(n_clusters=N_CLUSTERS, random_state=0).fit(data_subdict['algos']['umap']['embedding'])\n",
    "\n",
    "def cluster_to_colour(a):\n",
    "    return CLUSTER_COLOURS[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_labels = kmeans_lowdim.labels_ \n",
    "color_vector = [cluster_to_colour(a) for a in kmeans_labels]  # TODO currently unused\n",
    "\n",
    "clusterdata = {'color_vector': color_vector, \n",
    "               'cluster_ids': kmeans_labels,\n",
    "               'order': [str(a) for a in range(N_CLUSTERS)],\n",
    "               'cluster_to_idx': {a: np.where(kmeans_labels == a)[0] for a in range(N_CLUSTERS)}\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding with colour by cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_express_embedding(data_subdict, \n",
    "                         color_by_index=False, \n",
    "                         as_landscape=False, \n",
    "                         fmod='jupyter', \n",
    "                         show=False, \n",
    "                         dirpath=NOTEBOOK_OUTDIR, \n",
    "                         surf=False, \n",
    "                         step=None,\n",
    "                         clusterstyle=clusterdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot individual points from the clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES_PER_CLUSTER = 10\n",
    "\n",
    "from multicell.multicell_replot import \\\n",
    "    replot_graph_lattice_reference_overlap_plotter, replot_modern, replot_scatter_dots\n",
    "\n",
    "def plot_tissue_given_agg_idx(agg_index, fmod, outdir, state_int=False):\n",
    "    \n",
    "    # TODO do we need to load the varying simsetup_W in each dir of manyruns?\n",
    "    fpath_pickle = manyruns_path + os.sep + 'multicell_template.pkl'\n",
    "    with open(fpath_pickle, 'rb') as pickle_file:\n",
    "        multicell = pickle.load(pickle_file)  # unpickling multicell object\n",
    "\n",
    "    # update W as it may vary across agg indices of manyruns\n",
    "    # =======================================================================\n",
    "    # TODO: does manyruns/s0 correspond to agg0 in manyruns/aggregate\n",
    "    # =======================================================================\n",
    "    agg_datadir = manyruns_path + os.sep + 's%d' % agg_index\n",
    "    W_LOAD = np.loadtxt(agg_datadir + os.sep + 'simsetup' + os.sep + 'matrix_W.txt', delimiter=',')\n",
    "    #print(W_LOAD)\n",
    "    multicell.matrix_W = W_LOAD\n",
    "    multicell.simsetup['FIELD_SEND'] = W_LOAD\n",
    "    \n",
    "    # constants\n",
    "    num_cells = multicell.num_cells\n",
    "    simsetup = multicell.simsetup\n",
    "    sidelength = int(np.sqrt(num_cells)); assert sidelength ** 2 == num_cells\n",
    "    \n",
    "    #smod = ''\n",
    "    smod = '_last'\n",
    "    #if step is not None:\n",
    "    #    smod = '_%d' % step\n",
    "\n",
    "    agg_dir = manyruns_path + os.sep + 'aggregate'\n",
    "    fpath_state = agg_dir + os.sep + 'X_aggregate%s.npz' % smod\n",
    "    fpath_energy = agg_dir + os.sep + 'X_energy%s.npz' % smod\n",
    "    fpath_pickle = manyruns_path + os.sep + 'multicell_template.pkl'\n",
    "    print(fpath_state)\n",
    "    X = np.load(fpath_state)['arr_0'].T  # umap wants transpose\n",
    "    X_state = X[agg_index, :]\n",
    "    print(X_state.shape)\n",
    "\n",
    "    # plot option 2) using replot\n",
    "    X_state = X_state.reshape(num_cells, simsetup['N'])\n",
    "    \n",
    "    #outpath_ref = outdir + os.sep + 'agg%d_ref0' % agg_index\n",
    "    #replot_graph_lattice_reference_overlap_plotter(\n",
    "    #    X_state.T, sidelength, outpath_ref, fmod=fmod, ref_node=0)\n",
    "\n",
    "    outpath = outdir + os.sep + 'agg%d_modern' % agg_index\n",
    "    replot_modern(X_state.T, simsetup, sidelength, outpath,\n",
    "                  version='3', fmod=fmod, state_int=state_int)\n",
    "\n",
    "    outpath = outdir + os.sep + 'agg%d_scatter' % agg_index\n",
    "    replot_scatter_dots(X_state.T, sidelength, outpath,\n",
    "                        fmod=fmod, state_int=state_int)\n",
    "    return        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = data_subdict['algos']['umap']['embedding']\n",
    "print(kmeans_labels)\n",
    "print(embedding[0,:])\n",
    "\n",
    "for k in range(N_CLUSTERS):\n",
    "    indices = clusterdata['cluster_to_idx'][k]\n",
    "    num_points = min(SAMPLES_PER_CLUSTER, len(indices))\n",
    "    \n",
    "    cluster_outdir = NOTEBOOK_OUTDIR + os.sep + 'c%d' % k\n",
    "    assert not os.path.exists(cluster_outdir)\n",
    "    os.mkdir(cluster_outdir)\n",
    "    \n",
    "    for idx in range(num_points):\n",
    "        print(indices[idx])\n",
    "        agg_idx = indices[idx]\n",
    "        print('plotting cluster %d, example %d (agg %d)' % (k, idx, agg_idx))\n",
    "        \n",
    "        # now plot agg_idx as example of cluster N\n",
    "        plot_tissue_given_agg_idx(agg_idx, '', cluster_outdir)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
